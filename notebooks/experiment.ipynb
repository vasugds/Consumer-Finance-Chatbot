{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'regulations_1024_17.txt'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.consumerfinance.gov/rules-policy/regulations/1024/17/'\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "text_content = soup.get_text(separator='\\n', strip=True)\n",
    "file_path = 'regulations_1024_17.txt'\n",
    "with open(file_path, 'w', encoding='utf-8') as file:\n",
    "    file.write(text_content)\n",
    "\n",
    "file_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'base (Python 3.12.3)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n base ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "%pip install chainlit langchain langchain-community faiss-cpu ctransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'base (Python 3.12.3)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n base ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import TextLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter \n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.llms import CTransformers\n",
    "from langchain.chains import RetrievalQA\n",
    "import chainlit as cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'base (Python 3.12.3)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n base ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "DATA_PATH = 'C:\\Users\\User\\Downloads\\notebooks\\notebooks\\data'\n",
    "DB_FAISS_PATH = 'C:\\Users\\User\\Downloads\\notebooks\\notebooks\\vectorstore\\db_faiss'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vector_db():\n",
    "    loader = DirectoryLoader(DATA_PATH,\n",
    "                             glob='*.txt',\n",
    "                             loader_cls=TextLoader)\n",
    "\n",
    "    documents = loader.load()\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500,\n",
    "                                                   chunk_overlap=50)\n",
    "    texts = text_splitter.split_documents(documents)\n",
    "\n",
    "    embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2',\n",
    "                                       model_kwargs={'device': 'cpu'})\n",
    "\n",
    "    db = FAISS.from_documents(texts, embeddings)\n",
    "    db.save_local(DB_FAISS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = create_vector_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_prompt_template = \"\"\"Use the following pieces of information to answer the user's question.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Only return the helpful answer below and nothing else.\n",
    "Helpful answer:\n",
    "\"\"\"\n",
    "\n",
    "def set_custom_prompt():\n",
    "    \"\"\"\n",
    "    Prompt template for QA retrieval for each vectorstore\n",
    "    \"\"\"\n",
    "    prompt = PromptTemplate(template=custom_prompt_template,\n",
    "                            input_variables=['context', 'question'])\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieval_qa_chain(llm, prompt, db):\n",
    "    qa_chain = RetrievalQA.from_chain_type(llm=llm,\n",
    "                                       chain_type='stuff',\n",
    "                                       retriever=db.as_retriever(search_kwargs={'k': 2}),\n",
    "                                       return_source_documents=True,\n",
    "                                       chain_type_kwargs={'prompt': prompt}\n",
    "                                       )\n",
    "    return qa_chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_llm():\n",
    "    llm = CTransformers(\n",
    "        model = \"TheBloke/Llama-2-7B-Chat-GGML\",\n",
    "        model_type=\"llama\",\n",
    "        max_new_tokens = 512,\n",
    "        temperature = 0.5\n",
    "    )\n",
    "    return llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ctransformers\n",
      "  Downloading ctransformers-0.2.27-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: huggingface-hub in /Users/riteshyadav/miniforge3/envs/genai/lib/python3.10/site-packages (from ctransformers) (0.20.3)\n",
      "Collecting py-cpuinfo<10.0.0,>=9.0.0 (from ctransformers)\n",
      "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Requirement already satisfied: filelock in /Users/riteshyadav/miniforge3/envs/genai/lib/python3.10/site-packages (from huggingface-hub->ctransformers) (3.13.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/riteshyadav/miniforge3/envs/genai/lib/python3.10/site-packages (from huggingface-hub->ctransformers) (2024.3.1)\n",
      "Requirement already satisfied: requests in /Users/riteshyadav/miniforge3/envs/genai/lib/python3.10/site-packages (from huggingface-hub->ctransformers) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/riteshyadav/miniforge3/envs/genai/lib/python3.10/site-packages (from huggingface-hub->ctransformers) (4.66.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/riteshyadav/miniforge3/envs/genai/lib/python3.10/site-packages (from huggingface-hub->ctransformers) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/riteshyadav/miniforge3/envs/genai/lib/python3.10/site-packages (from huggingface-hub->ctransformers) (4.11.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/riteshyadav/miniforge3/envs/genai/lib/python3.10/site-packages (from huggingface-hub->ctransformers) (23.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/riteshyadav/miniforge3/envs/genai/lib/python3.10/site-packages (from requests->huggingface-hub->ctransformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/riteshyadav/miniforge3/envs/genai/lib/python3.10/site-packages (from requests->huggingface-hub->ctransformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/riteshyadav/miniforge3/envs/genai/lib/python3.10/site-packages (from requests->huggingface-hub->ctransformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/riteshyadav/miniforge3/envs/genai/lib/python3.10/site-packages (from requests->huggingface-hub->ctransformers) (2024.2.2)\n",
      "Downloading ctransformers-0.2.27-py3-none-any.whl (9.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Installing collected packages: py-cpuinfo, ctransformers\n",
      "Successfully installed ctransformers-0.2.27 py-cpuinfo-9.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ctransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qa_bot():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "                                       model_kwargs={'device': 'cpu'})\n",
    "    db = FAISS.load_local(DB_FAISS_PATH, embeddings, allow_dangerous_deserialization= True)\n",
    "    llm = load_llm()\n",
    "    qa_prompt = set_custom_prompt()\n",
    "    qa = retrieval_qa_chain(llm, qa_prompt, db)\n",
    "\n",
    "    return qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_result(query):\n",
    "    qa_result = qa_bot()\n",
    "    response = qa_result({'query': query})\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'base (Python 3.12.3)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n base ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "\n",
    "query_list = [\"What is escrow account?\", \"Limits on payments to escrow accounts\", \"What are some Methods of escrow account analysis.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'base (Python 3.12.3)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n base ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "for i in len(query_list):\n",
    "    response = []\n",
    "    response = final_result(query_list[i])\n",
    "    response.append(response)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cl.on_chat_start\n",
    "async def start():\n",
    "    chain = qa_bot()\n",
    "    msg = cl.Message(content=\"Starting the bot...\")\n",
    "    await msg.send()\n",
    "    msg.content = \"Hi, Welcome to Consumer Finance Bot. What is your query?\"\n",
    "    await msg.update()\n",
    "\n",
    "    cl.user_session.set(\"chain\", chain)\n",
    "\n",
    "@cl.on_message\n",
    "async def main(message: cl.Message):\n",
    "    chain = cl.user_session.get(\"chain\") \n",
    "    cb = cl.AsyncLangchainCallbackHandler(\n",
    "        stream_final_answer=True, answer_prefix_tokens=[\"FINAL\", \"ANSWER\"]\n",
    "    )\n",
    "    cb.answer_reached = True\n",
    "    res = await chain.acall(message.content, callbacks=[cb])\n",
    "    answer = res[\"result\"]\n",
    "    sources = res[\"source_documents\"]\n",
    "\n",
    "    if sources:\n",
    "        answer += f\"\\nSources:\" + str(sources)\n",
    "    else:\n",
    "        answer += \"\\nNo sources found\"\n",
    "\n",
    "    await cl.Message(content=answer).send()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
